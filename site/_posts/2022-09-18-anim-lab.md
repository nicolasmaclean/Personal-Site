---
title: Animation Lab
description: As Technical Director of the UT Dallas Animation Lab. I supported our Maya tools/pipeline and extended it to Unreal Engine 5.1
categories: [programming, tool]
tags: [Unreal, Maya, Python, PyQt5, PySide2]
---

{% include video.html type="post" name="BadTiming_Logo.mp4" class="pc-80 no-side-margin img-center" %}

# What is Animation Lab

Animation Lab is a course that aims to simulate a film studio environment. We had ~50 people over the course of 2 semesters (+1 more for a small pre-production team), during which we create a short, animated film. For Bad Timing (Spring - Fall 2022), we used Maya for everything from modeling to lighting with Substance Painter, Nuke, etc. For Red Hat Ringo (Spring - Fall 2023), we shifted to using Unreal 5.1 to render. Modeling, rigging, layout, and animation are still in Maya, but surfacing and lighting now work with Unreal.

We have a pipeline that manages the storing and sharing of files for each stage that has been/is being built across these films. As a technical director, I help fix bugs with the pipe, provide technical support, add features to the pipe, and create tools for artists.

## Bad Timing

I joined in the latter half of the film. Our pipeline was started a couple of years ago, so joining late didn't matter too much. I still had to overcome joining a project with a large, pre-existing codebase. My professor, Casey Johnson, didn't just throw all of that code at us. He gave us access to a handful of the modules. My fellow TD and I spent time looking around and experimenting to learn more about the pipe. As I settled in, I shifted to bug fixes and adding small features.

### Network

The biggest struggle we faced during Bad Timing was our network drive. A 3rd party provides the school with this drive for free and unforuntately the quality of their service has decreased over the years. It has gotten to the point that working with files on the network is so slow, we've been updating our code to minimize requests to the network or circumvent it altogether.

In practice, we leave our compiled code, project-wide data, and source files up there. But we download a copy of working files, work locally, and send versions/publishes back to the network. For the most part this is easy. Specific types of work like surfacing, hair grooms, assemblies, are little less simple. We have to carefully analyze those files before opening them for dependencies and make sure to download those too. It's a teidous process of modifying each stage of the pipe to do this, because we need to be extremely careful to not lose work.

I spent time upgrading our surfacing and xgen grooms to work locally. Unfortunately we had to ditch xgen for the final film, but it'll be there for the future.

---

## Red Hat Rigno

As mentioned before, we made the switch from Arnold to Unreal 5.1 for this film. To extend our pipe, I modified the existing file launcher to find/open unreal projects; automated the MovieRenderPipeline; and created a lookdev setup. To keep our workflow consistent, we opted to use Python and PySide2 instead of using C++ or blueprints. We have keep compiled code on the network that is appended to the PYTHONPATH at project startup.

### File Launcher

{% include image.html type="post" name="FileLauncher.png" class="pc-80 no-side-margin img-center" caption="Our Unreal Project Launcher" %}

Our file launcher queries the ShotGun API to gather data about our project and populate this GUI, which then allows artists to open specific assets or shots for a stage in the pipe. This process is smart in how it decides what file to open. It'll create an empty file (locally), if there is none; open a local file; or download the latest version from the network and open it.

In the future I would like to update this GUI to decrease the friction for an artist to begin working. But the Unreal portion of the pipe still has much more important stuff for the time being...

### Rendering

Although the MovieRenderPipeline is already quite a powerful tool for artists, I was tasked with automating the render process. This makes makes it easier for lighting artists not familiar with Unreal to render their work and allows the directors to more easily standardize settings across shots.

{% include image.html type="post" name="Rendering.png" class="pc-40 no-side-margin img-center" %}

This works by loading a rendering preset from an XML file stored on our network in the project-specific configs. I then have a set of convience methods and class to sit on top of Unreal's Python API that simplify the process of loading the queue and rendering it. The loaded preset can be sent there and the render begins.

---

## Reflection

Although I have loved this opportunity, there have been some tough portions. Somedays I just want to sit and code. Most of those times I can't. There are bugs, artists, or other issues that demand my attention, but that's just not how working is. No job is all sunshine. 

The aspect I had loved the most, was the chance to work so many talented artists and my fellow TD's. I've been collaborating directly with users of my work. They give me feedback, I watch how they use my tools and tweak accordingly, and they request cool things from me.

The unique position to work with such a diverse group of people is one of my favorite parts about tech art. Programmers in other fields, to some degree, are stuck in their own little bubble with other programmers. But I'm working with all of these amazing artists!